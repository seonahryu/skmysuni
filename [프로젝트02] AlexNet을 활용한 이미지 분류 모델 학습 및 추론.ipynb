{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chx_poSBqKrh"
   },
   "source": [
    "# [프로젝트2] AlexNet을 활용한 이미지 분류 모델 학습 및 추론\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6MJo3WJqQKV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noFfUTbPqRP9"
   },
   "source": [
    "\n",
    "## 실습 목표\n",
    "---\n",
    "- **목표 : AlexNet을 활용하여 이미지 분류 수행**\n",
    "  - AlexNet을 활용하여 딥러닝 기반 이미지 분류를 수행하고, 그 성능을 확인합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf7wuM_1ovNt"
   },
   "source": [
    "## 실습 목차\n",
    "---\n",
    "\n",
    "1. **학습 준비**: 딥러닝 모델을 구현하기 위한 라이브러리를 호출하고, 모델을 정의합니다. \n",
    "\n",
    "2. **데이터셋 및 데이터 로더 준비**: 학습에 필요한 데이터를 불러오고 전처리 합니다\n",
    "\n",
    "3. **손실 함수와 최적화 알고리즘 설정**: 모델의 학습을 위한 손실 함수와 최적화 함수(optimizer)를 정의합니다\n",
    "\n",
    "4. **학습 실행**: 앞서 정의한 데이터와 손실 함수, optimizer를 활용해 모델을 학습합니다.\n",
    "\n",
    "5. **모델 성능 평가**: 학습이 완료된 모델의 분류 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Hg41israe4"
   },
   "source": [
    "## 1. 학습 준비\n",
    "---\n",
    "필요 라이브러리를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5047,
     "status": "ok",
     "timestamp": 1688029600553,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "u73G3XwLtN9F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU를 사용할 수 있는지 확인합니다. GPU를 사용할 수 있다면 device에 cuda를, 사용할 수 없다면 cpu를 할당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFJPndpksLll"
   },
   "source": [
    "#### [TODO] AlexNet 모델을 정의해주세요.\n",
    "- AlexNet 모델을 정의하고, 가능하다면 모델을 GPU에 이동합니다. 그리고 모델의 구조를 출력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1688029601862,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "Rq3Zgby2tPdF",
    "outputId": "0e45136c-4603-4093-8fed-8badffe5d7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "******************************************************************\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# AlexNet 모델 정의\n",
    "model = models.alexnet(pretrained=False)\n",
    "# 최종 output layer 개수 1000개로 기본 설정되어 있으나, 출력 클래스 2개 할 것이므로 False\n",
    "print(model) # 원래 out_features=1000\n",
    "print(\"******************************************************************\")\n",
    "\n",
    "num_features = model.classifier[6].in_features # Classifier의 가장 마지막 layer의 input 개수\n",
    "model.classifier[6] = nn.Linear(num_features, 2)  # 출력 클래스 개수: 2 (tower, non-tower)\n",
    "\n",
    "# 가능하다면 GPU 사용\n",
    "model = model.to(device)\n",
    "\n",
    "# 모델의 구조 출력\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXgzRNsYsic8"
   },
   "source": [
    "## 2. 데이터셋 및 데이터 로더 준비\n",
    "---\n",
    "#### [TODO] 데이터 전처리를 위한 변환 과정을 정의해주세요. \n",
    "- 이미지 크기를 224, 224 로 조정하는 레이어를 추가해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688029606062,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "gLgxvdC2tTOv"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),           # 이미지를 Tensor로 변환\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 이미지 정규화 / 0~1 사이의 픽셀값을 해당값들의 평균과 표준편차로 변환하여 학습 진행\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tftwhJPslPj"
   },
   "source": [
    "#### [TODO] 데이터셋을 불러오고, 데이터 로더를 생성하는 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "data_path = \"/mnt/elice/dataset/classification_data/\"\n",
    "\n",
    "train_path = data_path + \"train/\"\n",
    "test_path = data_path + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4224,
     "status": "ok",
     "timestamp": 1688029610283,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "yGOnzUPvv-T9"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 로딩\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gZjAy_IstL2"
   },
   "source": [
    "## 3. 손실 함수와 최적화 알고리즘 설정\n",
    "---\n",
    "학습을 위한 손실 함수와 최적화 알고리즘 (optimizer)을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688029610284,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "tZtO6P2txzlH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# CrossEntropyLoss : 각 클래스의 확률값이 한 쪽 카테고리 값으로 크게 나타나면 loss 작아짐\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# momentum : 현재 업데이트되는 weight 값에 이전 단계 weight를 0.9 반영하여 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4Skb3sRs0D_"
   },
   "source": [
    "## 4. 학습 실행\n",
    "---\n",
    "10 epoch 만큼 학습을 진행합니다.\n",
    "- 학습에는 약 5분 정도 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688029610285,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "63C2PH2sFqSe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6902\n",
      "Epoch 2/10, Train Loss: 0.6787\n",
      "Epoch 3/10, Train Loss: 0.6673\n",
      "Epoch 4/10, Train Loss: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.6433\n",
      "Epoch 6/10, Train Loss: 0.6266\n",
      "Epoch 7/10, Train Loss: 0.6086\n",
      "Epoch 8/10, Train Loss: 0.5727\n",
      "Epoch 9/10, Train Loss: 0.5330\n",
      "Epoch 10/10, Train Loss: 0.4968\n",
      "학습 시간: 39.10748291015625 초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    # 이미지당 평균 loss 값\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"학습 시간: {training_time} 초\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 완료한 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "filename = f\"model_alexnet_sample1.pt\"\n",
    "torch.save(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfGK50Hgs5lo"
   },
   "source": [
    "## 5. 모델 성능 평가\n",
    "---\n",
    "테스트 데이터에 대해 모델의 성능을 평가합니다. 평가 지표로는 Accuracy를 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [TODO] 모델을 검증 모드로 변경해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135470,
     "status": "ok",
     "timestamp": 1688029750953,
     "user": {
      "displayName": "Unsang Park",
      "userId": "15627463023329626383"
     },
     "user_tz": -540
    },
    "id": "S63cUtRWocCq",
    "outputId": "ec3bfc54-b429-456e-9dec-733a0525af0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 검증 모드로 변환합니다\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.42%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1) # 1 열 단위로\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
